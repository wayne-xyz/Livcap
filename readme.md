

ToDo:
- [ ] VAD
- [ ] Chunking and ring buffer
- [ ] Multi-threading

- [ ] Prompting support for the whisper model
- [ ] Quantization support for speed up 


Note:
MLX-Swift only support safetensors file, using the convert.py to convert the .pt file to .safetensors file

- Privacy first, local model, no cloud, no analytics, no ads. No need internet connection. Free and open source. 
- Light weight and fast. One click to on/off.
- No annoying user analytics. If you think something can be improved, email me.
- Less is more. 

Usage:
Loading the file in : 
Livcap/CoreWhisperCpp/ggml-base.en.bin
Livcap/CoreWhisperCpp/ggml-tiny.en.bin
Livcap/CoreWhisperCpp/ggml-base.en-encoder.mlmodelc
Livcap/CoreWhisperCpp/ggml-tiny.en-encoder.mlmodelc